(window.webpackJsonp=window.webpackJsonp||[]).push([[51],{525:function(a,r,_){"use strict";_.r(r);var t=_(20),e=Object(t.a)({},(function(){var a=this,r=a.$createElement,_=a._self._c||r;return _("ContentSlotsDistributor",{attrs:{"slot-key":a.$parent.slotKey}},[_("h1",{attrs:{id:"消息中间件"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#消息中间件"}},[a._v("#")]),a._v(" 消息中间件")]),a._v(" "),_("h2",{attrs:{id:"_1、理论"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_1、理论"}},[a._v("#")]),a._v(" 1、理论")]),a._v(" "),_("h3",{attrs:{id:"_1-1-传统模式缺点"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_1-1-传统模式缺点"}},[a._v("#")]),a._v(" 1.1 传统模式缺点")]),a._v(" "),_("p",[a._v("并发量大的时候，所有的请求直接怼到数据库，造成数据库连接异常。")]),a._v(" "),_("h3",{attrs:{id:"_1-2-中间件模式优点"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_1-2-中间件模式优点"}},[a._v("#")]),a._v(" 1.2 中间件模式优点")]),a._v(" "),_("h4",{attrs:{id:"_1-2-1-解耦"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_1-2-1-解耦"}},[a._v("#")]),a._v(" 1.2.1 解耦")]),a._v(" "),_("p",[a._v("系统A在代码中直接调用系统B和系统C的代码，如果将来D系统接入，系统A还需要修改代码，过于麻烦！将消息写入消息队列，需要消息的系统自己从消息队列中订阅，从而系统A不需要做任何修改**。**")]),a._v(" "),_("h4",{attrs:{id:"_1-2-2-异步"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_1-2-2-异步"}},[a._v("#")]),a._v(" 1.2.2 异步")]),a._v(" "),_("h4",{attrs:{id:"_1-2-3-削峰"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_1-2-3-削峰"}},[a._v("#")]),a._v(" 1.2.3 削峰")]),a._v(" "),_("p",[a._v("系统A慢慢的按照数据库能处理的并发量，从消息队列中慢慢拉取消息。在生产中，这个短暂的高峰期积压是允许的。")]),a._v(" "),_("h3",{attrs:{id:"_1-3-消息队列缺点"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_1-3-消息队列缺点"}},[a._v("#")]),a._v(" 1.3 消息队列缺点")]),a._v(" "),_("h4",{attrs:{id:"_1-3-1-系统可用性减低"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_1-3-1-系统可用性减低"}},[a._v("#")]),a._v(" 1.3.1 系统可用性减低")]),a._v(" "),_("p",[a._v("消息队列挂了，相关系统功能受影响。")]),a._v(" "),_("h4",{attrs:{id:"_1-3-2-系统复杂度增加"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_1-3-2-系统复杂度增加"}},[a._v("#")]),a._v(" 1.3.2 系统复杂度增加")]),a._v(" "),_("p",[a._v("需要考虑很多方面问题，如重复消费问题、可靠传输（生产者弄丢数据、消息队列弄丢数据、消费者弄丢数据）问题、mq高可用（集群（镜像模式））等等。")]),a._v(" "),_("h2",{attrs:{id:"_2、rabbitmq"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_2、rabbitmq"}},[a._v("#")]),a._v(" 2、RabbitMQ")]),a._v(" "),_("h3",{attrs:{id:"_2-1-消息数量限制"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_2-1-消息数量限制"}},[a._v("#")]),a._v(" 2.1 消息数量限制")]),a._v(" "),_("p",[_("strong",[a._v("RabbitMQ上一个queue中存放的message是否有数量限制？")])]),a._v(" "),_("p",[a._v("可以认为是无限制的，因为限制取决于机器内存。")]),a._v(" "),_("h3",{attrs:{id:"_2-2-rabbitmq消息丢失"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_2-2-rabbitmq消息丢失"}},[a._v("#")]),a._v(" 2.2 RabbitMQ消息丢失")]),a._v(" "),_("p",[_("strong",[a._v("丢失数据分为：生产者丢失消息、消息列表丢失消息、消费者丢失消息。")])]),a._v(" "),_("h4",{attrs:{id:"_2-2-1-生产者丢失消息"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_2-2-1-生产者丢失消息"}},[a._v("#")]),a._v(" 2.2.1 生产者丢失消息")]),a._v(" "),_("p",[a._v("生产者丢失消息可以通过ACK方式处理，一旦消息投递到所有匹配的队列之后，rabbitMQ就会发送一个ACK给生产者。")]),a._v(" "),_("h4",{attrs:{id:"_2-2-2-消息列表丢失消息"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_2-2-2-消息列表丢失消息"}},[a._v("#")]),a._v(" 2.2.2 消息列表丢失消息")]),a._v(" "),_("p",[a._v("消息列表丢失可以开启持久化磁盘的配置，在消息持久化到磁盘后再给生产者发送ACK信号。")]),a._v(" "),_("p",[a._v("操作步骤：")]),a._v(" "),_("ul",[_("li",[a._v("将queue的持久化标识durable设置为true，则代表是一个持久的队列")]),a._v(" "),_("li",[a._v("发送消息的时候将deliveryMode=2")])]),a._v(" "),_("h4",{attrs:{id:"_2-2-3-消费者丢失消息"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_2-2-3-消费者丢失消息"}},[a._v("#")]),a._v(" 2.2.3 消费者丢失消息")]),a._v(" "),_("p",[a._v("消费者丢失消息一般是因为采用了自动确认消息模式，消费者在收到消息之后，处理消息之前会自动回复RabbitMQ已收到消息，如果这时处理消息失败，就会丢失消息。解决方案：")]),a._v(" "),_("ul",[_("li",[a._v("处理消息成功后，手动回复确认消息")])]),a._v(" "),_("h3",{attrs:{id:"_2-3-rabbitmq的消息投递流程是怎样的"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_2-3-rabbitmq的消息投递流程是怎样的"}},[a._v("#")]),a._v(" 2.3 RabbitMQ的消息投递流程是怎样的？")]),a._v(" "),_("p",[_("strong",[a._v("Producer --\x3e RabbitMQ Broker --\x3e Exchange --\x3e Queue --\x3e Consumer")])]),a._v(" "),_("h3",{attrs:{id:"_2-4-生产端怎么保证消息可靠性投递"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_2-4-生产端怎么保证消息可靠性投递"}},[a._v("#")]),a._v(" 2.4 生产端怎么保证消息可靠性投递？")]),a._v(" "),_("p",[_("strong",[a._v("消息从producer到exchange会返回一个confirmCallback。")])]),a._v(" "),_("p",[_("strong",[a._v("消息从exchange到queue投递失败会返回一个returnCallback。")])]),a._v(" "),_("p",[a._v("利用这两个callback可以控制消息的可靠性投递。")]),a._v(" "),_("ul",[_("li",[_("strong",[a._v("ConfirmCallback")])])]),a._v(" "),_("p",[a._v('设置publisher-confirm="true"开启确认模式。')]),a._v(" "),_("p",[a._v("在方法中判断ack，如果为true，则发送成功，如果为false，则发送失败。")]),a._v(" "),_("p",[_("img",{attrs:{src:"/img/media/10315c61d0ffe418b8466e302fd26275.png",alt:""}})]),a._v(" "),_("p",[_("img",{attrs:{src:"/img/media/9736c79d622b3efc71f56fb7f6d8f0cd.png",alt:""}})]),a._v(" "),_("ul",[_("li",[_("strong",[a._v("ReturnCallback")])])]),a._v(" "),_("p",[a._v('设置publisher-returns="true"开启退回模式。')]),a._v(" "),_("p",[a._v("消息从exchange路由到queue失败后触发回调。")]),a._v(" "),_("p",[_("img",{attrs:{src:"/img/media/bf586f827e1790a43aec251d2180eca8.png",alt:""}})]),a._v(" "),_("p",[_("img",{attrs:{src:"/img/media/2e003db99ae859eb2af8f0c42d3afec6.png",alt:""}})]),a._v(" "),_("h3",{attrs:{id:"_2-5-消费者收到消息后有几种确认方式"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_2-5-消费者收到消息后有几种确认方式"}},[a._v("#")]),a._v(" 2.5 消费者收到消息后有几种确认方式？")]),a._v(" "),_("p",[a._v("有三种确认方式：")]),a._v(" "),_("ul",[_("li",[a._v('自动确认：acknowledge="none" （自动ack）')]),a._v(" "),_("li",[a._v('手动确认：acknowledge="manual" （手动ack）')]),a._v(" "),_("li",[a._v('根据异常情况确认：acknowledge="auto",(这种方式使用麻烦，一般不用)')])]),a._v(" "),_("p",[_("strong",[a._v("自动确认")]),a._v("：消费者丢失消息一般是因为采用了自动确认消息模式，消费者在收到消息之后，处理消息之前会自动回复RabbitMQ已收到消息，如果这时处理消息失败，就会丢失消息。")]),a._v(" "),_("h3",{attrs:{id:"_2-6-rabbitmq消息重复消费"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_2-6-rabbitmq消息重复消费"}},[a._v("#")]),a._v(" 2.6 RabbitMQ消息重复消费")]),a._v(" "),_("h4",{attrs:{id:"_2-6-1-为什么会重复消费"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_2-6-1-为什么会重复消费"}},[a._v("#")]),a._v(" 2.6.1 为什么会重复消费？")]),a._v(" "),_("p",[a._v("正常情况，消费者在消费消息的时候，消费完毕会发送一个确认消息给消息队列，消息队列就知道该消息被消费了，就会将该消息从消息队列中删除。")]),a._v(" "),_("p",[a._v("但是因为网络传输等故障，确认消息没有传送到消息队列，导致消息队列不知道已经消费过该消息，再次将消息分发给其他消费者。")]),a._v(" "),_("h4",{attrs:{id:"_2-6-2-怎么解决消息重复消费问题"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_2-6-2-怎么解决消息重复消费问题"}},[a._v("#")]),a._v(" 2.6.2 怎么解决消息重复消费问题？")]),a._v(" "),_("p",[a._v("解决思路："),_("strong",[a._v("保证消息幂等性")])]),a._v(" "),_("h3",{attrs:{id:"_2-7-rabbitmq消息堆积"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_2-7-rabbitmq消息堆积"}},[a._v("#")]),a._v(" 2.7 RabbitMQ消息堆积")]),a._v(" "),_("h4",{attrs:{id:"_2-7-1-为什么会出现消息堆积"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_2-7-1-为什么会出现消息堆积"}},[a._v("#")]),a._v(" 2.7.1 为什么会出现消息堆积？")]),a._v(" "),_("p",[a._v("1.业务高峰期，请求量暴涨。")]),a._v(" "),_("p",[a._v("2.代码异常没有ack，或者全进入到私信。")]),a._v(" "),_("h4",{attrs:{id:"_2-7-2-怎么解决消息堆积问题"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_2-7-2-怎么解决消息堆积问题"}},[a._v("#")]),a._v(" 2.7.2 怎么解决消息堆积问题？")]),a._v(" "),_("p",[a._v("1.通过适度调高并发参数，提高服务消费能力。一般调整预取值prefetch和并发线程数concurrentcy。")]),a._v(" "),_("p",[a._v("2.增加消费节点，在数据库等扛得住的情况下，增加消费服务是一个优先选项。")]),a._v(" "),_("p",[a._v("3.异常导致的消息堆积，先紧急回滚代码，或紧急修复异常，然后按前两步提高消费能力。")]),a._v(" "),_("h3",{attrs:{id:"_2-8-什么是amqp协议"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_2-8-什么是amqp协议"}},[a._v("#")]),a._v(" 2.8 什么是AMQP协议？")]),a._v(" "),_("p",[_("strong",[a._v("Advanced Message Queuing Protocol，高级消息队列协议。是一个进程间传递异步消息的网络协议。")])]),a._v(" "),_("p",[_("img",{attrs:{src:"/img/media/ed1089b384a8683c83b79e741a46f308.png",alt:""}})]),a._v(" "),_("p",[_("strong",[a._v("工作过程：")])]),a._v(" "),_("p",[a._v("发布者（Publisher）发布消息（Message），经由交换机（Exchange）。")]),a._v(" "),_("p",[a._v("交换机根据路由规则将收到的消息分别发给与该交换机绑定的队列（Queue）。")]),a._v(" "),_("p",[a._v("最后 AMQP 代理会将消息投递给订阅了此队列的消费者（Consumer），或者消费者按照需求自行获取。")]),a._v(" "),_("h3",{attrs:{id:"_2-9-消息怎样才会进入死信队列"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_2-9-消息怎样才会进入死信队列"}},[a._v("#")]),a._v(" 2.9 消息怎样才会进入死信队列？")]),a._v(" "),_("p",[a._v("1）队列消息长度到达限制。")]),a._v(" "),_("p",[a._v("2）消费者拒接消费消息，basicNack/basicReject，并且不把消息放入原目标队列，requeue=false。")]),a._v(" "),_("p",[a._v("3）原队列存在消息过期设置，消息到达超时时间未被消费。")]),a._v(" "),_("h3",{attrs:{id:"_2-10-rabbitmq延迟队列是怎么实现的"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_2-10-rabbitmq延迟队列是怎么实现的"}},[a._v("#")]),a._v(" 2.10 RabbitMQ延迟队列是怎么实现的？")]),a._v(" "),_("p",[a._v("使用TTL+死信队列组合实现延迟队列效果。")]),a._v(" "),_("p",[a._v("TTL（time to live）消息存活时间：")]),a._v(" "),_("p",[a._v("如果消息在存活时间内未被消费，则会被清除。")]),a._v(" "),_("p",[a._v("RabbitMQ支持两种ttl设置：单独消息配置ttl；整个队列配置ttl（居多）")]),a._v(" "),_("p",[a._v("需求：")]),a._v(" "),_("p",[a._v("1.下单后，30分钟未支付，取消订单，回滚库存。")]),a._v(" "),_("p",[a._v("2.新用户注册成功7天后，发送短信问候。")]),a._v(" "),_("p",[_("img",{attrs:{src:"/img/media/59e1ace806815eae0223c0908a86c929.png",alt:""}})]),a._v(" "),_("h3",{attrs:{id:"_2-11-rabbitmq有哪些工作模式"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_2-11-rabbitmq有哪些工作模式"}},[a._v("#")]),a._v(" 2.11 RabbitMQ有哪些工作模式？")]),a._v(" "),_("p",[a._v("简单模式")]),a._v(" "),_("p",[a._v("work queue")]),a._v(" "),_("p",[a._v("publish/subscribe发布订阅模式")]),a._v(" "),_("p",[a._v("routing路由模式")]),a._v(" "),_("p",[a._v("topics 主题模式")]),a._v(" "),_("p",[a._v("rpc远程调用模式")]),a._v(" "),_("p",[_("img",{attrs:{src:"/img/media/7bddc0c0e566ac7549d3f5527a950262.png",alt:"1555988678324"}})]),a._v(" "),_("h3",{attrs:{id:"_2-12-rabbitmq怎么保证高可用"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_2-12-rabbitmq怎么保证高可用"}},[a._v("#")]),a._v(" 2.12 RabbitMQ怎么保证高可用？")]),a._v(" "),_("p",[a._v("镜像集群模式")]),a._v(" "),_("p",[_("img",{attrs:{src:"/img/media/b890e0029c1ad602cf3f08b1f1cf0efe.png",alt:""}})]),a._v(" "),_("p",[a._v("1.生产者向任一服务节点注册队列，该队列相关信息会同步到其他节点上。。")]),a._v(" "),_("p",[a._v("2.任一消费者向任一节点请求消费，可以直接获取到消费的消息，因为每个节点上都有相同的实际数据。")]),a._v(" "),_("p",[a._v("3.任一节点宕机，不影响消息在其他节点上进行消费。")]),a._v(" "),_("p",[a._v("缺点")]),a._v(" "),_("p",[a._v("1.性能开销非常大，因为要同步消息到对应的节点，这个会造成网络之间的数据量的频繁交互，对于网络带宽的消耗和压力都是比较重的。")]),a._v(" "),_("p",[a._v("2.没有扩展可言，rabbitMQ是集群，不是分布式的，所以当某个Queue负载过重，我们并不能通过新增节点来缓解压力，因为所以节点上的数据都是相同的，这样就没办法进行扩展了。")]),a._v(" "),_("p",[a._v("对于镜像集群而言，当某个queue负载过重，可能会导致集群雪崩，那么如何来减少集群雪崩呢？我们可以通过HA的同步策略来实现")]),a._v(" "),_("p",[a._v("HA的同步策略如下：")]),a._v(" "),_("p",[_("img",{attrs:{src:"/img/media/368e86995f0389611a7ed44eaffcf2bd.png",alt:""}})]),a._v(" "),_("h3",{attrs:{id:"_2-13-rabbitmq怎么保证消息消费的顺序性"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_2-13-rabbitmq怎么保证消息消费的顺序性"}},[a._v("#")]),a._v(" 2.13 RabbitMQ怎么保证消息消费的顺序性？")]),a._v(" "),_("p",[a._v("1.RabbitMQ的queue本身就是队列，是可以保证消息的"),_("strong",[a._v("顺序投递")]),a._v("的。")]),a._v(" "),_("p",[a._v("2.但是顺序消费就是另一回事了，要保证顺序消费可以通过以下做法：")]),a._v(" "),_("p",[a._v("1）投递消息的时候加上时间戳，消费端通过时间戳判断先后顺序。")]),a._v(" "),_("p",[a._v("2）同一字段的更新，设定只有一个消费者，但是这样效率低。")]),a._v(" "),_("h2",{attrs:{id:"_3、kafka"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_3、kafka"}},[a._v("#")]),a._v(" 3、Kafka")]),a._v(" "),_("h3",{attrs:{id:"_3-1-通信模型"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_3-1-通信模型"}},[a._v("#")]),a._v(" 3.1 通信模型")]),a._v(" "),_("p",[_("img",{attrs:{src:"/img/media/68822c6c2a59844ed62d290f54c64a49.png",alt:""}})]),a._v(" "),_("table",[_("thead",[_("tr",[_("th",[_("strong",[a._v("名称")])]),a._v(" "),_("th",[_("strong",[a._v("解释")])])])]),a._v(" "),_("tbody",[_("tr",[_("td",[a._v("Broker")]),a._v(" "),_("td",[a._v("消息中间件处理节点，一个Kafka节点就是一个broker，一个或者多个Broker可以组成一个Kafka集群")])]),a._v(" "),_("tr",[_("td",[a._v("Topic")]),a._v(" "),_("td",[a._v("Kafka根据topic对消息进行归类，发布到Kafka集群的每条消息都需要指定一个topic")])]),a._v(" "),_("tr",[_("td",[a._v("Partition")]),a._v(" "),_("td",[a._v("物理上的概念，一个topic可以分为多个partition，每个partition内部消息是有序的")])]),a._v(" "),_("tr",[_("td",[a._v("Consumer")]),a._v(" "),_("td",[a._v("消息消费者，从Broker读取消息的客户端")])]),a._v(" "),_("tr",[_("td",[a._v("ConsumerGroup")]),a._v(" "),_("td",[a._v("每个Consumer属于一个特定的Consumer Group，一条消息可以被多个不同的Consumer Group消费，但是一个Consumer Group中只能有一个Consumer能够消费该消息")])]),a._v(" "),_("tr",[_("td",[a._v("Producer")]),a._v(" "),_("td",[a._v("消息生产者，向Broker发送消息的客户端")])])])]),a._v(" "),_("h3",{attrs:{id:"_3-2-kafka概念"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_3-2-kafka概念"}},[a._v("#")]),a._v(" 3.2 kafka概念")]),a._v(" "),_("h4",{attrs:{id:"_3-2-1-topic-partition"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_3-2-1-topic-partition"}},[a._v("#")]),a._v(" 3.2.1 Topic & Partition")]),a._v(" "),_("ul",[_("li",[a._v("每个partition，都对应一个commit log文件。")]),a._v(" "),_("li",[a._v("每个partition都有一个唯一编号：offset。")]),a._v(" "),_("li",[a._v("每个consumer都是基于自己在commit log中的offset进行工作的。Offset由consumer自己维护。")])]),a._v(" "),_("p",[_("img",{attrs:{src:"/img/media/cd889f9c64107209dd5e8827749d95ec.png",alt:""}})]),a._v(" "),_("p",[_("strong",[a._v("为什么topic数据要分区存储？")])]),a._v(" "),_("p",[a._v("1、分区之后可以将不同的分区放在不同的机器上，相当于对数据做了分布式存储")]),a._v(" "),_("p",[a._v("2、提高并行度")]),a._v(" "),_("p",[a._v("数据存储：server.properties log.dirs=/usr/local/data/kafka-logs")]),a._v(" "),_("p",[a._v("Kafka Broker 有一个参数，log.segment.bytes，限定了每个日志段文件的大小，最大就是 1GB。")]),a._v(" "),_("p",[a._v("一个日志段文件满了，就自动开一个新的日志段文件来写入，避免单个文件过大，影响文件的读写性能，这个过程叫做 log rolling，正在被写入的那个日志段文件，叫做 active log segment。")]),a._v(" "),_("h4",{attrs:{id:"_3-2-2-consumer-consumergroup"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_3-2-2-consumer-consumergroup"}},[a._v("#")]),a._v(" 3.2.2 Consumer & ConsumerGroup")]),a._v(" "),_("ul",[_("li",[a._v("一个partition同一个时刻在一个consumer group中只能有一个consumer在消费，从而保证消费顺序。")]),a._v(" "),_("li",[a._v("consumer group中的consumer的数量不能比一个Topic中的partition的数量多，否则多出来的consumer消费不到消息。")])]),a._v(" "),_("p",[_("img",{attrs:{src:"/img/media/d234005bff9c889150587ca02e0265a9.png",alt:""}})]),a._v(" "),_("p",[a._v("Kafka只在partition的范围内保证消息消费的局部顺序性，不能在同一个topic中的多个partition中保证总的消费顺序性。")]),a._v(" "),_("p",[a._v("如果有在总体上保证消费顺序的需求，那么我们可以通过将topic的partition数量设置为1，将consumer group中的consumer instance数量也设置为1，但是这样会影响性能，所以kafka的顺序消费很少用。")]),a._v(" "),_("h4",{attrs:{id:"_3-2-3-producer"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_3-2-3-producer"}},[a._v("#")]),a._v(" 3.2.3 Producer")]),a._v(" "),_("p",[_("strong",[a._v("写入方式")])]),a._v(" "),_("p",[a._v("producer 采用 push 模式将消息发布到 broker，每条消息都是被append到patition中，属于顺序写磁盘")]),a._v(" "),_("p",[_("strong",[a._v("消息路由")])]),a._v(" "),_("p",[a._v("producer发送消息到broker时，会根据分区算法选择将其存储到哪一个partition。其路由机制为：")]),a._v(" "),_("p",[a._v("1.指定了patition，则直接使用；")]),a._v(" "),_("p",[a._v("2.未指定patition 但指定key，通过对key的value进行hash选出一个patition。")]),a._v(" "),_("p",[a._v("3.patition和key都未指定，使用轮询选出一个patition。")]),a._v(" "),_("p",[_("strong",[a._v("消息确认机制")])]),a._v(" "),_("p",[_("strong",[a._v("acks=0")]),a._v("：表示producer不需要等待任何broker确认收到消息的回复，就可以继续发送下一条消息。")]),a._v(" "),_("p",[_("strong",[a._v("acks=1")]),a._v("：至少要等待leader已经成功将数据写入本地log，但不需要等待所有follower是否成功写入。")]),a._v(" "),_("p",[_("strong",[a._v("acks=-1或all")]),a._v("：leader需要等待所有备份(min.insync.replicas配置的备份个数)都成功写入日志")]),a._v(" "),_("p",[_("strong",[a._v("acks=-1时的数据流程：")])]),a._v(" "),_("p",[_("img",{attrs:{src:"/img/media/5b8027bb58f1eff3df2f06db64ddbb01.png",alt:""}})]),a._v(" "),_("p",[a._v('1.producer先从zookeeper 的 "/brokers/.../state" 节点找到该partition的leader。')]),a._v(" "),_("p",[a._v("2.producer将消息发送给该leader。")]),a._v(" "),_("p",[a._v("3.leader将消息写入本地log。")]),a._v(" "),_("p",[a._v("4.followers从leader pull消息，写入本地log后向leader发送ACK。")]),a._v(" "),_("p",[a._v("5.leader收到"),_("strong",[a._v("所有ISR中")]),a._v("的replica的ACK后，增加HW（high watermark，最后 commit 的 offset）并向producer发送ACK。")]),a._v(" "),_("h3",{attrs:{id:"_3-3-选举机制"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_3-3-选举机制"}},[a._v("#")]),a._v(" 3.3 选举机制")]),a._v(" "),_("p",[_("strong",[a._v("Controller选举机制")])]),a._v(" "),_("p",[a._v("kafka集群启动的时候，会自动选举一台broker作为controller来管理整个集群，选举的过程是集群中每个broker都会尝试在zookeeper上创建一个 /controller 临时节点，zookeeper会保证有且仅有一个broker能创建成功，这个broker就会成为集群的总控器controller。")]),a._v(" "),_("p",[_("strong",[a._v("Partition副本选举Leader机制")])]),a._v(" "),_("p",[a._v("controller感知到分区leader所在的broker挂了，会从ISR列表里挑第一个broker作为leader")]),a._v(" "),_("p",[a._v("(参数unclean.leader.election.enable=false的前提下。")]),a._v(" "),_("p",[a._v("参数unclean.leader.election.enable为true，则ISR列表里所有副本都挂了的时候可以在ISR列表外的副本中选leader，")]),a._v(" "),_("p",[a._v("这种设置，可以提高可用性，但是选出的新leader有可能数据少很多。)")]),a._v(" "),_("p",[_("strong",[a._v("副本进入ISR列表有两个条件:")])]),a._v(" "),_("p",[a._v("1.必须能与zookeeper保持会话以及跟leader副本网络连通")]),a._v(" "),_("p",[a._v("2.副本能复制leader上的所有写操作，并且不能落后太多。(与leader副本同步滞后的副本，是由 replica.lag.time.max.ms配置决定的，超过这个时间都没有跟leader同步过的一次的副本会被移出ISR列表)")]),a._v(" "),_("h3",{attrs:{id:"_3-4-hw与leo"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_3-4-hw与leo"}},[a._v("#")]),a._v(" 3.4 HW与LEO")]),a._v(" "),_("p",[a._v("LEO （Log End Offset）")]),a._v(" "),_("p",[a._v("HW有两个主要的作用：")]),a._v(" "),_("p",[a._v("1、用于实现副本备份机制（replication）；")]),a._v(" "),_("p",[a._v("2、定义消息可见性，即HW之下的所有消息对consumer是可见的。如果没有HW机制，就需要其他手段来实现这两个功能。")]),a._v(" "),_("p",[_("img",{attrs:{src:"/img/media/3caf278f3fa5f0b33a8414ac0e65ae09.jpeg",alt:""}})]),a._v(" "),_("h3",{attrs:{id:"_3-5-kafka核心总控制器controller"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_3-5-kafka核心总控制器controller"}},[a._v("#")]),a._v(" 3.5 kafka核心总控制器Controller")]),a._v(" "),_("p",[a._v("在Kafka集群中会有一个或者多个broker，其中有一个broker会被选举为控制器(Kafka Controller)，它负责管理整个集群中所有分区和副本的状态。")]),a._v(" "),_("p",[_("strong",[a._v("主题管理")])]),a._v(" "),_("p",[a._v("完成对Kafka主题的创建、删除以及分区增加的操作")]),a._v(" "),_("p",[_("strong",[a._v("分区重分配")])]),a._v(" "),_("p",[a._v("对已有主题分区进行细粒度的分配功能")]),a._v(" "),_("p",[_("strong",[a._v("集群成员管理")])]),a._v(" "),_("p",[a._v("自动检测新增Broker、Broker主动关闭、Broker宕机.")]),a._v(" "),_("p",[a._v("/brokers/ids/下面会存放Broker实例的id临时节点，当我们看到/brokers/ids下面有几个节点，就表示有多少个存活的Broker实例。")]),a._v(" "),_("p",[a._v("当Broker宕机时，临时节点就会被删除，此时控制器对应的监听器就会感知到Broker下线，进而完成对应的下线工作。")]),a._v(" "),_("p",[_("strong",[a._v("数据服务")])]),a._v(" "),_("p",[a._v("向其它Broker提供数据服务，控制器上保存了最全的集群元数据信息,")]),a._v(" "),_("p",[a._v("其它Broker会定期接收控制器发来的元数据更新请求，从而更新其内存中的缓存数据")]),a._v(" "),_("h3",{attrs:{id:"_3-6-kafka高性能原因"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_3-6-kafka高性能原因"}},[a._v("#")]),a._v(" 3.6 kafka高性能原因")]),a._v(" "),_("ul",[_("li",[_("strong",[a._v("磁盘顺序读写")]),a._v("：kafka消息不能修改以及不会从文件中间删除保证了磁盘顺序读，kafka的消息写入文件都是追加在文件末尾。")]),a._v(" "),_("li",[a._v("**PageCache：**Kafka重度依赖底层操作系统提供的磁盘高速缓存PageCache（内核缓冲区）功能。"),_("br"),a._v("\n当上层有写操作时，操作系统只是将数据写入PageCache，同时标记Page属性为Dirty。内存池再异步地写到磁盘上。"),_("br"),a._v("\n当读操作发生时，先从PageCache中查找，如果发生缺页才进行磁盘调度，最终返回需要的数据。"),_("br"),a._v("\n实际上PageCache是把尽可能多的空闲内存都当做了磁盘缓存来使用。"),_("br"),a._v("\n同时如果有其他进程申请内存，回收PageCache的代价又很小，所以现代的OS都支持PageCache。")]),a._v(" "),_("li",[a._v("**零拷贝：**linux操作系统 “零拷贝” 机制使用了sendfile方法， 允许操作系统将数据从Page Cache 直接发送到网络，只需要最后一步的copy操作将数据复制到 NIC 缓冲区， 这样避免重新复制数据 。通过这种 “零拷贝” 的机制，Page Cache 结合 sendfile 方法，Kafka消费端的性能也大幅提升。这也是为什么有时候消费端在不断消费数据时，我们并没有看到磁盘io比较高，此刻正是操作系统缓存在提供数据。")])]),a._v(" "),_("p",[_("img",{attrs:{src:"/img/media/ba780739db784b6737d6662faecfe011.png",alt:""}}),a._v(" "),_("img",{attrs:{src:"/img/media/654e570272d1d4edff52cd2997188a58.jpeg",alt:""}})]),a._v(" "),_("ul",[_("li",[_("strong",[a._v("批量读写、批量压缩")])])]),a._v(" "),_("h3",{attrs:{id:"_3-7-线上规划"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_3-7-线上规划"}},[a._v("#")]),a._v(" 3.7 线上规划")]),a._v(" "),_("p",[_("img",{attrs:{src:"/img/media/f8909a1dd7ff0e3dcaf6f2362890735c.png",alt:""}})])])}),[],!1,null,null,null);r.default=e.exports}}]);