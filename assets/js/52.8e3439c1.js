(window.webpackJsonp=window.webpackJsonp||[]).push([[52],{526:function(a,e,t){"use strict";t.r(e);var s=t(20),_=Object(s.a)({},(function(){var a=this,e=a.$createElement,t=a._self._c||e;return t("ContentSlotsDistributor",{attrs:{"slot-key":a.$parent.slotKey}},[t("h1",{attrs:{id:"elasticsearch"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#elasticsearch"}},[a._v("#")]),a._v(" Elasticsearch")]),a._v(" "),t("h2",{attrs:{id:"_1、canal"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1、canal"}},[a._v("#")]),a._v(" 1、canal")]),a._v(" "),t("h3",{attrs:{id:"_1-1-什么是canal"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-1-什么是canal"}},[a._v("#")]),a._v(" 1.1 什么是canal？")]),a._v(" "),t("p",[a._v("canal是用java开发的基于数据库增量日志解析，提供增量数据订阅&消费的中间件。")]),a._v(" "),t("p",[a._v("目前，canal主要支持MySQL的binlog解析，解析完成才利用canal client用来处理获得的相关数据。数据库同步需要阿里的otter中间件，基于canal。")]),a._v(" "),t("h3",{attrs:{id:"_1-2-canal的工作原理"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-2-canal的工作原理"}},[a._v("#")]),a._v(" 1.2 canal的工作原理？")]),a._v(" "),t("p",[t("img",{attrs:{src:"/img/media/965b346d431e963d274a26fa583a0396.png",alt:""}})]),a._v(" "),t("p",[a._v("首先了解一下mysql主备复制原理：")]),a._v(" "),t("p",[a._v("（1）master主库将改变记录，发送到二进制文件（binary log）中")]),a._v(" "),t("p",[a._v("（2）slave从库向mysql Master发送dump协议，将master主库的binary log events拷贝到它的中继日志（relay log）")]),a._v(" "),t("p",[a._v("（3）slave从库读取并重做中继日志中的事件，将改变的数据同步到自己的数据库")]),a._v(" "),t("p",[t("img",{attrs:{src:"/img/media/d4b3c8207e1b9dc2a8c8cd1ebbabf043.png",alt:""}})]),a._v(" "),t("p",[t("strong",[a._v("canal的工作原理")])]),a._v(" "),t("p",[a._v("把自己伪装成slave，从master复制数据。读取binlog是需要master授权的，因为binlog是加密的，授权分用户名密码才能读。")]),a._v(" "),t("p",[a._v("master授权后不知道读他的binlog的是从机还是canal，他的所有传输协议都符合从机的标准，所以master一直以为是从机读的。")]),a._v(" "),t("h3",{attrs:{id:"_1-3-canal高可用"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-3-canal高可用"}},[a._v("#")]),a._v(" 1.3 canal高可用？")]),a._v(" "),t("p",[a._v("有两个canal服务器都监控一个或多个mysql服务器的binlog，这两个canal服务同时只能有一个提供服务。")]),a._v(" "),t("p",[a._v("当提供服务的这个宕机时，zookeeper能知道，zookeeper就通知另一个canal服务器让他提供服务。")]),a._v(" "),t("p",[a._v("当原来宕机的那个再启动起来时，是抢占模式的，谁抢到就谁上，没抢到就standy模式。")]),a._v(" "),t("p",[a._v("canal本身就是一个工具不存数据，宕机了就宕机，只有还有另外一个能提供服务就行，所以没有什么同步问题（不像数据库有同步问题）。")]),a._v(" "),t("h3",{attrs:{id:"_1-4-canal投递消息到kafka"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-4-canal投递消息到kafka"}},[a._v("#")]),a._v(" 1.4 canal投递消息到kafka")]),a._v(" "),t("p",[a._v("1.canal投递消息到kafka，可指定mysql库表，支持按库表指定字段hash投递的kafka的partition。")]),a._v(" "),t("p",[a._v("2.canal投递到kafka的消息体，例如：")]),a._v(" "),t("p",[a._v('ConsumerRecord(topic = binlog, partition = 0, offset = 29, CreateTime = 1647331490778, serialized key size = -1, serialized value size = 52, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = {"event":"datatest.user.update","value":[999,"ccc"]})')]),a._v(" "),t("p",[a._v('ConsumerRecord(topic = binlog, partition = 1, offset = 21, CreateTime = 1647331490777, serialized key size = -1, serialized value size = 62, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = "{\\"event\\":\\"datatest.user.update\\",\\"value\\":[999,\\"ccc\\"]}")')]),a._v(" "),t("p",[a._v('ConsumerRecord(topic = binlog, partition = 0, offset = 30, CreateTime = 1647268549467, serialized key size = -1, serialized value size = 276, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = {"data":[{"id":"999","name":"ccc"}],"database":"datatest","es":1647331490000,"id":8,"isDdl":false,"mysqlType":{"id":"int(11)","name":"varchar(50)"},"old":[{"name":"bbb"}],"pkNames":["id"],"sql":"","sqlType":{"id":4,"name":12},"table":"user","ts":1647268549466,"type":"UPDATE"})')]),a._v(" "),t("h2",{attrs:{id:"_2、mysql的binlog"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2、mysql的binlog"}},[a._v("#")]),a._v(" 2、mysql的binlog")]),a._v(" "),t("h3",{attrs:{id:"_2-1-什么是binlog"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2-1-什么是binlog"}},[a._v("#")]),a._v(" 2.1 什么是binlog？")]),a._v(" "),t("p",[a._v("mysql的二进制日志，记录了所有的DDL和DML（除了数据查询语句），以事件的形式进行记录，包含语句执行消耗的时间，mysql的二进制日志是事务安全型的。")]),a._v(" "),t("p",[a._v("开启二进制日志大概会有1%的性能损坏。")]),a._v(" "),t("p",[a._v("二进制日志有2个主要的使用场景：")]),a._v(" "),t("p",[a._v("① mysql的主备复制")]),a._v(" "),t("p",[a._v("② 数据恢复，通过使用mysqlbinlog工具来恢复数据")]),a._v(" "),t("p",[a._v("（用这个做恢复是备选方案，主方案还是定期快照，定期执行脚本导数据，其实就是把当前所有数据导成insert，这个量少）")]),a._v(" "),t("p",[a._v("二进制日志包括2类文件：")]),a._v(" "),t("p",[a._v("①二进制日志索引文件（后缀为.index）用于记录所有的二进制文件")]),a._v(" "),t("p",[a._v("②二进制日志文件（后缀为.00000*）记录数据库所有的DDL和DML（除了数据查询语句）")]),a._v(" "),t("h3",{attrs:{id:"_2-2-怎么开启binlog"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2-2-怎么开启binlog"}},[a._v("#")]),a._v(" 2.2 怎么开启binlog？")]),a._v(" "),t("p",[t("strong",[a._v("1.修改my.cnf配置")])]),a._v(" "),t("p",[t("img",{attrs:{src:"/img/media/fbb3c6cbcb1cd00b9ab2e912f56696d6.png",alt:""}})]),a._v(" "),t("p",[t("strong",[a._v("2.重启mysql")])]),a._v(" "),t("p",[t("img",{attrs:{src:"/img/media/267d9b5880ab1d4202ed4d35a85c4e65.png",alt:""}})]),a._v(" "),t("p",[t("strong",[a._v("3.查看开启状态")])]),a._v(" "),t("p",[a._v("输入 show variables like 'log_bin'; 查看binlog开启状态。如下图所示。")]),a._v(" "),t("p",[t("img",{attrs:{src:"/img/media/53d55f39637e69915ddcb28c38b6122e.png",alt:""}})]),a._v(" "),t("p",[a._v("输入 show variables like 'binlog_format'; 查看Binary Log记录方式。如下图所示。")]),a._v(" "),t("p",[t("img",{attrs:{src:"/img/media/873d05ce5750ce9a431606c33ccdaf70.png",alt:""}})]),a._v(" "),t("h3",{attrs:{id:"_2-3-binlog有几种格式"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2-3-binlog有几种格式"}},[a._v("#")]),a._v(" 2.3 binlog有几种格式？")]),a._v(" "),t("p",[a._v("binlog的格式有三种：STATEMENT,MIXED,ROW对比如下")]),a._v(" "),t("p",[t("img",{attrs:{src:"/img/media/42786f01727173d7fad525ed1b715c99.png",alt:""}})]),a._v(" "),t("h3",{attrs:{id:"_2-4-binlog格式怎么选择"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2-4-binlog格式怎么选择"}},[a._v("#")]),a._v(" 2.4 binlog格式怎么选择？")]),a._v(" "),t("p",[a._v("如果只考虑主从复制的话可以用mixed。")]),a._v(" "),t("p",[a._v("抽取数据用于统计分析之类的话用row。")]),a._v(" "),t("h2",{attrs:{id:"_3、oracle-goldengate-ogg"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_3、oracle-goldengate-ogg"}},[a._v("#")]),a._v(" 3、Oracle GoldenGate（ogg）")]),a._v(" "),t("h3",{attrs:{id:"_3-1-什么是ogg"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_3-1-什么是ogg"}},[a._v("#")]),a._v(" 3.1 什么是ogg？")]),a._v(" "),t("p",[a._v("GoldenGate软件是一种基于日志的结构化数据复制软件，它通过解析源数据库在线日志或归档日志获得数据的增量变化，再将这些变化应用到目标 数据库，从而实现源数据库与目标数据库同步。")]),a._v(" "),t("p",[a._v("GoldenGate可以实现一对一、广播(一对多)、聚合(多对一)、双向、点对点、级联等多种拓扑结构。")]),a._v(" "),t("h2",{attrs:{id:"_4、日志系统实现思路"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_4、日志系统实现思路"}},[a._v("#")]),a._v(" 4、日志系统实现思路")]),a._v(" "),t("p",[a._v("1."),t("strong",[a._v("业务入口生成唯一traceId -> 发送kafka落日志文件（包含此次操作的用户信息）")])]),a._v(" "),t("p",[t("strong",[a._v("-> 数据变更落数据库（包含traceId）")])]),a._v(" "),t("p",[a._v("2."),t("strong",[a._v("binglog -> kafka ->")]),a._v(" "),t("strong",[a._v("有traceId变更的数据解析落日志文件（包含本次变更的所有字段）")])]),a._v(" "),t("p",[a._v("3."),t("strong",[a._v("flume收集日志 -> kafka -> flink接收日志并清洗 -> 写入es（相同traceId关联成一条数据）")])]),a._v(" "),t("h2",{attrs:{id:"_5、elasticsearch"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_5、elasticsearch"}},[a._v("#")]),a._v(" 5、Elasticsearch")]),a._v(" "),t("p",[t("img",{attrs:{src:"/img/media/ec98116d99661863e733eb5e2f715b3d.png",alt:""}})]),a._v(" "),t("h3",{attrs:{id:"_5-1-elasticsearch的倒排索引是什么"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_5-1-elasticsearch的倒排索引是什么"}},[a._v("#")]),a._v(" 5.1 elasticsearch的倒排索引是什么？")]),a._v(" "),t("p",[a._v("例如：查询指定关键词的文章。")]),a._v(" "),t("p",[a._v("传统的检索是：遍历文章找到有对应的关键词。")]),a._v(" "),t("p",[a._v("倒排索引：通过分词策略，形成词和文章的映射关系表，这种词典+映射表即为倒排索引。")]),a._v(" "),t("p",[t("img",{attrs:{src:"/img/media/0fc04ccec7d4ec4d12e2489f8309f6fe.png",alt:""}})]),a._v(" "),t("h3",{attrs:{id:"_5-2-elasticsearch索引数据多了怎么办"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_5-2-elasticsearch索引数据多了怎么办"}},[a._v("#")]),a._v(" 5.2 elasticsearch索引数据多了怎么办？")]),a._v(" "),t("p",[a._v("1.使用滚动索引。基于模板+时间+rollover api滚动创建索引。")]),a._v(" "),t("p",[a._v("2.只保留指定时间范围内数据。")]),a._v(" "),t("p",[a._v("3.动态增加节点。ES自身支持动态扩展。")]),a._v(" "),t("h3",{attrs:{id:"_5-3-说说公司es的集群架构-索引数据大小-分片有多少"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_5-3-说说公司es的集群架构-索引数据大小-分片有多少"}},[a._v("#")]),a._v(" 5.3 说说公司ES的集群架构，索引数据大小，分片有多少？")]),a._v(" "),t("p",[t("strong",[a._v("集群架构")])]),a._v(" "),t("p",[a._v("ES的集群架构有23个节点，节点配置是16核64G的。")]),a._v(" "),t("p",[t("strong",[a._v("索引数据大小")])]),a._v(" "),t("p",[a._v("该集群架构包括了订单服务和运单服务的索引，其中我们负责的运单服务包括寄件运单和派件运单索引。")]),a._v(" "),t("p",[a._v("索引根据录入时间每日递增（滚动索引）。当时每日新增数据两个索引大概四五千万，数据大小几十G。")]),a._v(" "),t("p",[t("strong",[a._v("分片数量")])]),a._v(" "),t("p",[a._v("10个分片。5个主分片和5个副本分片。")])])}),[],!1,null,null,null);e.default=_.exports}}]);