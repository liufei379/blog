---
title: redis
date: 2022-04-28 18:14:52
permalink: /pages/26e33d/
categories:
  - 知识整理
tags:
  - Redis
author: 
  name: liuwenkai01
---


# Redis

## 1、什么是位图？

**一个由1亿个数组成的集合M，范围从1\~10亿。新来一个数n，如何快速且地判断是否存在M中？**

申请一个大小为10亿，数据类型为布尔的“特殊”散列表，将这一亿个数作为散列表下标，将值设成True。

![](/img/media/c478d004a3786149f03a11f299d76438.png) 

不过很多语言的布尔大小是1字节，并不能节省很大空间，实际上只需要使用1个二进制位，来表示true和false两个值就行了。

这就要用到位运算了，借助编程语言提供的数据类型，比如int，char等，通过位运算，用其中的某个位表示某个数字。 这就是**位图**。

**![](/img/media/67948bce4fa90a80813022f7578fa696.png)**

消耗大小：约120M。

**操作平台拦截件使用了位图实现！**

## 2、什么是布隆过滤器？

位图有个问题，想想看，如果数的范围是1到100亿呢，那位图消耗的大小就是1.2G了！！，相对于散列表，不降反升。 这个时候，**布隆过滤器**登场了，它其实是对位图一种改进。

-   针对数据范围是1到100亿的集合，还是申请10亿的二进制大小的位图（消耗内存120M）
-   使用多个哈希函数，得到k个不同的哈希值，记为 x1,x2,x3...xk。将k个数字作为位图中的下标，将对应的值设为1

**![](/img/media/a916a5e470530ebb563b5ad8ade4aeac.png)**

-   适当选择k个哈希函数，k个哈希值都相同的概率就非常低了，但又会带来新的问题，那就是误判

**![](/img/media/cb25bcd69934cb04e138a1431f8b89d0.png)**

-   布隆过滤器的误判有个特点：

**没有就是没有，有就有极低的可能会没有。**

## 3、redis怎么进行过期删除？

我们set key的时候，都可以给一个expire time，就是过期时间，通过过期时间我们可以指定这个key可以存活的时间。

如果假设你设置了一批key只能存活1个小时，那么接下来1小时后，redis是怎么对这批key进行删除的?

**定期删除+惰性删除。**

### 3.1 定期删除

redis默认是每隔 **100ms** 就随机抽取一些设置了过期时间的key，检查其是否过期，如果过期就删除。注意这里是随机抽取的。为什么要随机呢?你想一想假如 redis 存了几十万个 key ，每隔100ms就遍历所 有的设置过期时间的 key 的话，就会给 CPU 带来很大的负载!

### 3.2 惰性删除

定期删除可能会导致很多过期 key 到了时间并没有被删除掉。所以就有了惰性删除。假如你的过期 key，靠定期删除没有被删除掉，还停留在内存里，除非你的系统去查一下那个 key，才会被redis给删除掉。这就是所谓的惰性删除，也是够懒的哈!

但是仅仅通过设置过期时间还是有问题的。我们想一下:如果定期删除漏掉了很多过期 key，然后你也没及时去查， 也就没走惰性删除，此时会怎么样?如果大量过期key堆积在内存里，导致redis内存块耗尽了。怎么解决这个问题呢? -- **redis内存淘汰机制。**

### 3.3 主动清理策略

**根据自身业务类型，配置好maxmemory-policy(默认是noeviction)，**

**推荐使用volatile-lru。**

主动清理策略在Redis4.0之前一共实现了6种**内存淘汰策略**，在4.0之后，又增加了2种策略，总共8种策略：

#### a) 针对设置了过期时间的key做处理：

##### 3.3.1 volatile-ttl

在筛选时，会针对设置了过期时间的键值对，根据过期时间的先后进行删除，越早过期的越先被删除。

##### 3.3.2 volatile-random

就像它的名称一样，在设置了过期时间的键值对中，进行随机删除。

##### 3.3.3 volatile-lru

会使用 LRU 算法筛选设置了过期时间的键值对删除。

##### 3.3.4 volatile-lfu

会使用 LFU 算法筛选设置了过期时间的键值对删除。

#### b) 针对所有的key做处理：

##### 3.3.5 allkeys-random

从所有键值对中随机选择并删除数据。

##### 3.3.6 allkeys-lru

使用 LRU 算法在所有数据中进行筛选删除。

##### 3.3.7 allkeys-lfu

使用 LFU 算法在所有数据中进行筛选删除。

#### c) 不处理：

##### 3.3.8 noeviction

不会剔除任何数据，拒绝所有写入操作并返回客户端错误信息"(error) OOM command not allowed when used memory"，此时Redis只响应读操作。

### 3.4 LFU、LRU数据淘汰策略

#### 3.4.1 LRU

LRU 算法(Least Recently Used，最近最少使用)

淘汰很久没被访问过的数据，以**最近一次访问时间**作为参考。

#### 3.4.2 LFU

LFU 算法(Least Frequently Used，最不经常使用)

淘汰最近一段时间被访问次数最少的数据，以**次数**作为参考。

#### 3.4.3 配置建议

当存在热点数据时，**LRU**的效率很好，但偶发性的、周期性的批量操作会导致LRU命中率急剧下降，缓存污染情况比较严重。这时使用**LFU**可能更好点。

## 4、Redis最大内存配置

一般推荐Redis设置最大内存**maxmemory**为最大物理内存的四分之三。

![](/img/media/c7b9efa73f31b780ab3dfb4b17cbe588.png)

如果不设置最大内存，当 Redis 内存超出物理内存限制时，内存的数据会开始和磁盘产生频繁的交 换 (swap)，会让 Redis 的性能急剧下降。

当Redis运行在主从模式时，只有主结点才会执行过期删除策略，然后把删除操作”del key”同步到从结点删除数据。

## 5、Redis怎么做持久化的？

Redis支持持久化，而且支持两种不同的持久化操作。

**Redis的一种持久化方式叫快照(snapshotting，RDB)。**

**另一种方式是只追加文件(append-only file,AOF)。**

### 5.1 RDB持久化(快照持久化)

RDB持久化是将内存中的数据以快照的方式写进二进制文件中，默认的文件名为：dump.rdb。

**快照持久化是Redis默认采用的持久化方式**。

#### 5.1.1 RDB持久化是怎么触发的？

**RDB支持3种触发方式：save，bgsave，自动化。**

##### 5.1.1.1 save触发方式

该命令会阻塞redis服务器，命令执行期间redis不能执行其他命令，直到RDB过程结束。

![](/img/media/e03ed58801da1a3a0ad379dc409ff54d.png)

##### 5.1.1.2 bgsave触发方式

该命令不会阻塞redis服务器，命令执行期间redis还可以响应客户端需求。

具体过程是redis进程执行fork操作创建一个子进程，RDB持久化过程由该子进程负责，完成后自动结束。阻塞只发生在fork阶段，一般时间很短**。Redis内部所有RDB操作基本上都是用bgsave命令。**

![](/img/media/88b798b1dd4b5e79f82821b8aaf5bb47.png)

##### 5.1.1.3 自动触发方式

自动触发是由我们配置文件来完成的。在redis.conf配置文件中默认有此下配置:

save 900 1 \#在900秒(15分钟)之后，如果至少有1个key发生变化，Redis就会自动触发**bgsave**命令创建快照。

save 300 10 \#在300秒(5分钟)之后，如果至少有10个key发生变化，Redis就会自动触发**bgsave**命令创建快照。

save 60 10000 \#在60秒(1分钟)之后，如果至少有10000个key发生变化，Redis就会自动触发**bgsave**命令创建快照。

#### 5.1.2 RDB有什么优势和劣势？

##### 5.1.2.1 RDB优势

1）RDB文件紧凑，全量备份，非常适合数据备份和灾难恢复。

2）RDB过程可通过子线程进行，不影响redis主线程。

3）恢复大数据集时，恢复速度比AOF恢复速度快。

##### 5.1.2.1 RDB劣势

快照持久化期间修改的数据不会被保存，可能丢失数据。

### 5.2 AOF持久化(append-only file)

AOF的工作机制很简单，就是redis把每一个收到的写命令都追加保存到AOF文件中。

与快照持久化相比，AOF持久化 的实时性更好，因此已成为主流的持久化方案。

**默认情况下Redis没有开启**。

AOF(append only file)方式的持久化，可以通过appendonly参数开启: **appendonly yes**

#### 5.2.1 AOF的持久化是怎么触发的？

在Redis的配置文件中存在三种不同的 AOF 持久化方式，它们分别是:

##### 5.2.1.1 appendfsync always

每次有数据修改发生时都会写入AOF文件,这样会严重降低Redis的速度。

##### 5.2.1.2 appendfsync everysec

异步操作，每秒钟同步一次数据到硬盘，如果1秒内宕机，有数据丢失。

##### 5.2.1.3 appendfsync no

让操作系统决定何时进行同步。

#### 5.2.2 AOF持久化3种触发方式的对比？

![](/img/media/38f940b5119a6cc859b2e2d75c4284f2.png)

#### 5.2.3 AOF方式什么时候会出现文件重写？

由于AOF方式会记录所有的写命令，对于同一份数据来说，AOF日志文件要比RDB快照文件更大。随着持久化文件越来越大，redis会fork出子线程来将文件进行重写。

![](/img/media/7f33fa214ed8a710cc19617c6ff64ec9.png)

**重写AOF文件不会读取旧文件，而是将内存中的数据内容用命令的方式重写一个新的AOF文件。**

#### 5.2.4 AOF有什么优势和劣势？

##### 5.2.4.1 AOF优势

1）AOF可以更好地保护数据不丢失，一般设置每隔1秒同步一次数据，所以最多丢失1秒的数据。

2）AOF日志文件每次写入数据都是追加，写入性能很高。

3）AOF可以后台操作，不影响客户端读写。

4）AOF非常适合针对误删等情况进行数据恢复。比如有人不小心执行了flushall命令清空了数据，可以通过删除AOF文件中最后一条flushall命令，再将AOF文件放回去，执行恢复操作，恢复所有数据。

##### 5.2.4.2 AOF劣势

1）针对同一份数据，AOF日志文件通常比RDB快照文件大。

### 5.3 混合持久化

**RDB和AOF的特点：**

![](/img/media/944b104913f11a8b192a02246e206701.png)

Redis 4.0 带来了一个新的持久化选项——混合持久化。

重启 Redis 时，我们很少使用 RDB来恢复内存状态，因为会丢失大量数据。我们通常使用 AOF 日志重放，但是重放 AOF 日志性能相对 RDB来说要慢很多，这样在 Redis 实例很大的情况下，启动需要花费很长的时间。

**通过如下配置可以开启混合持久化(必须先开启aof):**

\#aof‐use‐rdb‐preambleyes

![](/img/media/83c1071129c2b10e00b8fd93056964c8.png) 

AOF在重写时，不再是单纯将内存数据转换为RESP命令写入AOF文件，而是将重写这一刻之前的内存做RDB快照处理，并且**将RDB快照内容和增量的AOF修改内存数据的命令存在一起，都写入新的AOF文件**，重写完新的AOF文件覆盖原有的AOF文件，完成新旧两个AOF文件的替换。

### 5.4 数据怎么恢复？

**例：**

![](/img/media/7a2255808964c6f67eb27c19e8808142.png)

## 6、缓存雪崩｜缓存击穿｜缓存穿透

### 6.1 缓存雪崩

#### 6.1.1 什么是缓存雪崩？

缓存同一时间大面积失效，后面请求全部落到数据库，造成数据库短时间内承受大量请求而崩掉。

#### 6.1.2 缓存雪崩有什么解决方案？

**事前：**

1）尽量保证整个redis集群高可用，发现机器宕机尽快补上。

2）缓存失效时间可以在原来的基础上加多一个随机值，避免同一时间集体失效。

**事中：**

开启限流或者降级，避免Mysql崩掉。

**事后：**

利用redis持久化机制保存的数据尽快恢复缓存。

### 6.2 缓存击穿

#### 6.2.1 什么是缓存击穿？

**Key对应的数据存在**，但是在redis未缓存或者已经过期，此时大量请求过来，由于redis中不存在，需要去数据库查询之后再回写redis缓存，造成大量请求直接打在数据库上，很容易把数据库压垮。

#### 6.2.2 缓存击穿有什么解决方案？

1）定时任务主动刷新缓存。

2）通过加锁的方式解决，用普通jvm的锁就可以。

查缓存时能命中则直接返回，不能命中则需要获取锁才能进行下一步访问数据库等操作。

![](/img/media/eca8ee22dcef8bab5693996a9fb1d808.png)

### 6.3 缓存穿透

#### 6.3.1 什么是缓存穿透？

**Key对应的数据不存在**，一般是黑客故意去请求缓存中不存在的数据，导致所有的请求都落到数据库上，造成数据库短时间内承受大量请求而崩掉。

#### 6.3.2 缓存穿透有什么解决方案？

1）最简单粗暴的办法，如果一个查询返回的数据为空（不管数据不存在，还是系统故障），仍然把这个空结果进行缓存，但它的过期时间会很短，最长不超过五分钟。

2）采用布隆过滤器，将有值的key存放到布隆过滤器中，则没有值的key必然会被过滤掉。

## 7、Redis集群

### 7.1 主从复制

#### 7.1.1 全量复制

![](/img/media/74f356c78ea0d121d2187da9285d3ea9.png)

1.如果你为master配置了一个slave，不管这个slave是否是第一次连接上Master，它都会发送一个PSYNC命令给master请求复制数据。

2.master收到PSYNC命令后，会在后台进行数据持久化通过bgsave生成最新的rdb快照文件。

3.持久化期间，master会继续接收客户端的请求，它会把这些可能修改数据集的请求缓存在内存中。

4.当持久化进行完毕以后，master会把这份rdb文件数据集发送给slave，slave会把接收到的数据进行持久化生成rdb，然后再加载到内存中。

5.然后，master再将之前缓存在内存中的命令发送给slave。

6.当master与slave之间的连接由于某些原因而断开时，slave能够自动重连Master，如果master收到了多 个slave并发连接请求，它只会进行一次持久化，而不是一个连接一次，然后再把这一份持久化的数据发送给多个并发连接的slave。

#### 7.1.2 部分复制、断点续传

![](/img/media/0e9c0ccea0394e5d51608fa77ea22d7f.png)

1.master会在其内存中创建一个复制数据用的缓存队列，缓存最近一段时间的数据。

2.master和它所有的slave都维护了复制的数据下标offset和master的进程id，因此，当网络连接断开后，slave会请求master继续进行未完成的复制，从所记录的数据下标开始。

3.如果master进程id变化了，或者从节点数据下标offset太旧，已经不在master的缓存队列里了，那么将会进行一次全量数据的复制。

#### 7.1.3 主从复制风暴

如果有很多从节点，为了缓解主从复制风暴(多个从节点同时复制主节点导致主节点压力过大)，可以做如 下架构，让部分从节点与从节点(与主节点同步)同步数据。

![](/img/media/8f807f8504dbc0fb6e5a18ad59163005.png)

### 7.2 哨兵模式

![](/img/media/69f60bd672a57faa36c0174ef0b2c67c.png)

1.sentinel哨兵是特殊的redis服务，不提供读写服务，主要用来监控redis实例节点。

2.哨兵架构下client端第一次从哨兵找出redis的主节点，后续就直接访问redis的主节点，不会每次都通过 sentinel代理访问redis的主节点，当redis的主节点发生变化，哨兵会第一时间感知到，并且将新的redis主节点通知给client端。

**缺点：**

1.哨兵的配置较复杂。

2.主从切换的瞬间存在**访问瞬断**的情况。

3.哨兵模式只有一个主节点对外提供服务，没法支持很高并发。且单个主节点内存不宜设置得过大，否则会导致持久化文件过大，影响数据恢复或主从同步的效率。

### 7.3 高可用集群模式

![](/img/media/765f8355bd428de36fbd2297a622bd98.png)

集群模式没有中心节点，可水平扩展，可以线性扩展到上万个节点(官方推荐不超过1000个节点)。

Redis Cluster 将所有数据划分为 16384 个 slots(槽位)，每个节点负责其中一部分槽位。槽位的信息存储于每个节点中。

**槽位定位算法**

Cluster 默认会对 key 值使用 crc16 算法进行 hash 得到一个整数值，然后用这个整数值对16384进行取模来得到具体槽位。

**HASH_SLOT = CRC16(key) mod 16384**

### 7.4 Redis集群节点间的通信机制

**集中式:**

优点在于元数据的更新和读取，时效性非常好，一旦元数据出现变更立即就会更新到集中式的存储中，其他节点读取的时候立即就可以立即感知到;不足在于所有的元数据的更新压力全部集中在一个地方，可能导致元数据的存储压力。 很多中间件都会借助zookeeper集中式存储元数据。

**Redis集群节点间采用gossip协议进行通信。**

![](/img/media/4e0de8bb65e06a89538741d3082e5ab6.png)

gossip协议包括多种消息，包括ping，pong，meet，fail等等。

**优点：**

元数据更新比较分散，不是集中在一个地方，更新请求会陆陆续续，打到所有节点上去更新，有一定延时，降低了压力。

**缺点：**

元数据更新有延时可能导致集群的一些操作会有一些滞后。

![](/img/media/c0549c0ae97157c8b808ab6929ddd596.png)

![](/img/media/3ecb79a872d72f33efff8a924beeccfa.png)

### 7.5 Redis集群选举

#### 7.5.1 选举流程

当slave发现自己的master变为FAIL状态时，便尝试进行Failover，以期成为新的master。由于挂掉的master 可能会有多个slave，从而存在多个slave竞争成为master节点的过程， 其过程如下:

1.slave发现自己的master变为FAIL。

2.将自己记录的集群currentEpoch加1，并广播FAILOVER_AUTH_REQUEST信息。

3.其他节点收到该信息，只有master响应，判断请求者的合法性，并发送FAILOVER_AUTH_ACK，对每一个 epoch只发送一次ack。

4.尝试failover的slave收集master返回的FAILOVER_AUTH_ACK。

5.**slave收到超过半数master的ack**后变成新Master。

(这里解释了集群为什么至少需要三个主节点，如果只有两个，当其中一个挂了，只剩一个主节点是不能选举成功的)

6.slave广播Pong消息通知其他集群节点。

从节点并不是在主节点一进入 FAIL 状态就马上尝试发起选举，而是有一定延迟，一定的延迟确保我们等待 FAIL状态在集群中传播，slave如果立即尝试选举，其它masters或许尚未意识到FAIL状态，可能会拒绝投票。

延迟计算公式:

**DELAY = 500ms + random(0 \~ 500ms) + SLAVE_RANK \* 1000ms**

SLAVE_RANK表示此slave已经从master复制数据的总量的rank。Rank越小代表已复制的数据越新。这种方式下，持有最新数据的slave将会首先发起选举(理论上)。

#### 7.5.2 集群脑裂问题

Redis集群没有过半机制会有脑裂问题，网络分区导致脑裂后多个主节点对外提供写服务，一旦网络分区恢复，会将其中一个主节点变为从节点，这时会有大量数据丢失。

#### 7.5.3 Redis集群为什么至少要三个master节点，并且推荐奇数？

选举新master需要大于半数的集群master节点同意才能选举成功，如果只有两个master节点，挂了一个，就达不到过半数选举的条件。

奇数个master节点可以在满足选举条件的基础上节省一个节点。比如三个master跟四个master，大家挂了一个都可以选举新master，挂了两个都不可以选举新master。所以奇数的master节点更多的是从**节省机器资源**角度出发说的。

### 7.2 Redis集群下可以执行批量操作命令吗？

Redis集群是没法执行批量操作命令的，如mget，pipeline等。这是因为redis将集群划分为16383个哈希槽，不同的key会划分到不同的槽中。

但是，Jedis客户端提供了计算key的slot方法，以及slot和节点之间的映射关系，通过这两个数据，就可以计算出每个key所在的节点，然后使用pipeline获取数据。

### 7.3 Redis集群支持多数据库吗？

Redis集群是不支持多数据库的，只有一个数据库空间，默认 SELECT 0，即db0。

### 7.4 Redis集群不足的地方？

1.集群模式下做批量操作比较麻烦，需要自己计算处理。

2.假如有一个key，对应的value是hash类型的，不支持映射到集群的不同节点。

### 7.5 Redis集群方案什么情况下会导致集群不可用？

当redis.conf的配置cluster-require-full-coverage为no时，表示当负责一个插槽的主节点下线且没有相应的从节点进行故障恢复时，集群仍然可用，如果为yes则集群不可用。

## 8、Redis基础

### 8.1 Redis是单线程的吗？

**Redis 的单线程主要是指 Redis 的网络 IO（即一个线程处理所有网络请求） 和键值对读写是由一个线程来完成的**，这也是 Redis 对外 提供键值存储服务的主要流程。但 Redis的其他功能，比如持久化、异步删除、集群数据同步等，其实是由额外的线程执行的。

### 8.2 Redis单线程为什么还能这么快？

**因为Redis所有数据都在内存中，所有的运算都是内存级别的运算，而且单线程避免了多线程的切换性能损耗问题。**

正因为Redis是单线程的，所有要小心使用Redis指令，对于那些耗时的指令（比如keys），一定要谨慎使用，一不小心就可能会导致Redis卡顿。

### 8.3 Redis单线程如何处理那么多的并发客户端连接？

**核心是利用epoll来使用IO多路复用。**

Redis基于**Reactor模式**开发了自己的网络事件处理器，称之为文件事件处理器。文件事件处理器由**Socket**、**IO多路复用程序**、**文件事件分派器**、**事件处理器**四部分组成。

![](/img/media/ce3a583097ca8caa1c4fb85258d726b2.png)

IO多路复用程序会把所有产生事件的socket压入一个队列中，然后有序地每次仅一个socket的方式传送给文件事件分派器，文件事件分派器接收到socket之后会根据socket产生的事件类型调用对应的事件处理器进行处理。

**Reactor模式**

![](/img/media/f6eecf2af0ba96a3f5f5cada6d8e81ec.png)

Reactor模式：基于事件驱动的设计，当有事件触发时，才会调用处理器进行数据处理。  
从结构上，这有点类似生产者消费者模式，即有一个或多个生产者将事件放入一个Queue中，而一个或多个消费者主动的从这个Queue中Poll事件来处理；  
而Reactor模式则并没有Queue来做缓冲，每当一个Event输入到Service Handler之后，  
该Service Handler会主动的根据不同的Event类型将其分发给对应的Request Handler来处理。

### 8.4 Redis支持哪些数据类型？

Redis主要支持5种数据类型，分别是：

string（字符串），hash（哈希），list（列表），set（集合），zset（有序集合）

**string:**

string类型是redis最基本的数据类型，一个键最大能存储512M

示例：增加：set name "testname" 查看：get name

**hash:**

hash是一个string类型的field和value的映射表。hash特别适合存储对象。

示例：增加：hset myhash myfield1 "hello" myfield2 "world" 查看：hget myhash myfield2

**list:**

list是简单的字符串列表。可以从队头或者队尾插入元素。

示例：增加：lpush mytestlist value1 value2 查看：lrange mytestlist 0 10

**set:**

set是string类型的无序集合，集合成员是唯一的。

示例：增加：sadd mytestset value1 查看：smembers mytestset

**zset:**

zset是一个有序的set集合，每个元素会关联一个double型的分数，分数可以重复。

示例：增加：zadd mytestzset 1 value1 查看：zrange mytestzset 0 10 withscores

### 8.5 Redis的单点吞吐量？

单点TPS达8万/秒，QPS达10万/秒。

### 8.6 其他高级命令

keys:全量遍历键，用来列出所有满足特定正则字符串规则的key，当redis数据量比较大时，性能比较差，要避免使用。

## 9、Redisson

### 9.1 使用例子

redission支持4种连接redis方式，分别为单机、主从、Sentinel、Cluster 集群。项目中使用的是集群模式。

![](/img/media/50f57230c58881599269326a7fb986a5.png) 

![](/img/media/ae339415a5cf29ec36cc29584ecac967.png) 

![](/img/media/12e7fea6f58f57fbfe68b9651eae32df.png) 

### 9.2 分布式锁演变过程

#### 9.2.1 SETNX

![](/img/media/c8ff3c2f593afdf43c840ac0cf017383.png)

**存在问题：**

1）客户端所在节点奔溃，无法正确释放锁。

2）业务逻辑异常，无法释放锁。

#### 9.2.2 超时设置

设置超时时间，到点锁自动释放。

SETNX lock:168 1 // 获取锁(integer) 1\>

EXPIRE lock:168 60 // 60s 自动删除(integer) 1

**存在问题：**

1）「加锁」、「设置超时」是两个命令，不是原子操作。可能出现只执行了第一条命令，第二条没执行成功的情况。

**解决方案：**

Redis 2.6.x之后，官方拓展了SET命令的参数，支持设置超时时间，并且满足原子性。

set key_name random_value nx px 30000

nx 表示只有key_name不存在才能设值成功。

px 30000 表示30秒后自动过期。

#### 9.2.3 只能释放自己的锁

**存在问题：**

自己的锁可能被别人释放。

比如：

1.线程1获取锁成功并设置30秒后超时。

2.线程1由于某些原因执行很慢（网络问题、fullGC问题等...），超过30秒还没执行完，此时Redis因为锁过期自动释放了锁。

3.线程2获取锁执行自己业务。

4.线程1执行完自己业务释放锁，结果此时释放成线程2的锁。

**解决方案：**

加锁的时候设置一个「唯一标识」作为value，释放锁的时候用自己的唯一标识和value作比较，匹配上才能释放锁。

**加锁：**

set key_name **random_value** nx px 30000

**释放锁：**

if (redis.get("key_name").equals(random_value)) {

//比对成功则删除

redis.del("key_name");

}

**问题：**释放锁时这种写法存在一个问题，get和del是两个操作，存在原子性问题。

可以通过Lua脚本实现原子性：

// 获取锁的 value 与 ARGV[1] 是否匹配，匹配则执行

delif redis.call("get",KEYS[1]) == ARGV[1]

then return redis.call("del",KEYS[1])

else return 0

end

#### 9.2.4 正确设置锁超时

超时时间的设置一般为：通过多轮压测，取平均时间的3 \~ 5倍。

但即使这样仍然可能出现问题，可以通过以下方式完善超时时间设置：

给获取锁的线程添加一个守护线程，该守护线程定期检测锁的失效时间，如果锁快要失效，但是业务还没执行完，就对这个锁进行续期，重新设置超时时间。

#### 9.2.5 实现可重入锁

![](/img/media/548968f7c4dc577794968cfec3581402.png)

通过redis hash结构实现可重入锁。

**加锁：**

1.加锁时先使用redis exists判断key_name这个锁是否存在。

2.如果锁不存在，使用hincrby创建一个key_name的hash表，random_value对应的value_count初始化为0再加1。

3.如果key_name存在，用hexists判断random_value这个键存不存在，如果random_value存在，value_count使用hincrby加1，否则加锁失败。

**解锁：**

1.不存在key_name或不存在random_value，解锁失败。

2.存在指定random_value，则使用hincrby减1，当value_count小于等于0，使用del删除这把锁。释放锁成功。

### 9.3 Redis分布式锁存在什么缺点？

由于redis集群同步数据的方式是异步，假设master节点获取到锁之后未完成数据同步就挂了，这个时候在新的master节点依然可以获取锁，所以多个客户端会同时获取到锁。